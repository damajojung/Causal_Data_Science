{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "749c9ce3",
   "metadata": {},
   "source": [
    "# Causal Data Science Week 4 Tutorial\n",
    "\n",
    "In this tutorial, we will cover two additional methods for identifying estimands from a causal graph: frontdoor criterion and instrumental variables. We will also show how to calculate causal estimates based on these estimands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c25a5d3",
   "metadata": {},
   "source": [
    "### Frontdoor Criterion\n",
    "\n",
    "The frontdoor criterion is similar to the backdoor criterion, only now we move along 'forward' paths rather than 'backwards' paths. The below definition and example are from: https://medium.data4sci.com/causal-inference-part-xii-front-door-criterion-38bec5172f3e.\n",
    "\n",
    "A set of variables **Z** is said to satisfy the front-door criterion relative to an ordered pair of variables ($X_i$, $X_j$), if:\n",
    "1. **Z** intercepts all directed paths from $X_i$ to $X_j$\n",
    "2. There is no unblocked backdoor path from $X_i$ to **Z**\n",
    "3. All backdoor paths from **Z** to $X_j$ are blocked by $X_i$\n",
    "\n",
    "Let's consider the same graph as in week 3 and identify possible frontdoor criterion adjustment sets for the effect of $X$ on $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721ca9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we import networkx and create a directed graph\n",
    "import networkx as nx\n",
    "G = nx.DiGraph()\n",
    "\n",
    "G.add_nodes_from(['A', 'B', 'C', 'D', 'W', 'X', 'Y', 'Z'])\n",
    "\n",
    "G.add_edges_from([('B','A'), ('B','Z'), ('C','Z'), ('C','D'), \n",
    "                  ('A','X'), ('Z','X'), ('Z','Y'), ('D','Y'),\n",
    "                 ('X','W'), ('W','Y')])\n",
    "\n",
    "# we can visualise this graph (choosing node positions, colours, and sizes to make it more clear) \n",
    "# and save it to a .gml format (for using DoWhy later)\n",
    "pos = {'B': (-1, 1),              'C': (1, 1),\n",
    "         'A': (-1, 0), 'Z': (0, 0), 'D': (1, 0),\n",
    "         'X': (-1, -1), 'W': (0, -1), 'Y': (1, -1),}\n",
    "nx.draw(G, pos= pos, with_labels=True, node_size=500, node_color='w', edgecolors ='black')\n",
    "nx.write_gml(G, \"frontdoor_criterion_graph.gml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ebfb20",
   "metadata": {},
   "source": [
    "In this tutorial, we will create a DoWhy CausalGraph object, which has many functions built-in that calculate what we did manually in the previous tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7452d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dowhy\n",
    "import pandas as pd\n",
    "from dowhy import CausalModel\n",
    "\n",
    "# once again we use arbitrary data, since we are still focused on the graph and not data\n",
    "df = pd.DataFrame({'A':[1],'B':[1],'C':[1],'D':[1],'W':[1],'X':[1],\n",
    "                  'Y': [1], 'Z': [1]})\n",
    "\n",
    "# a utility function to parse the .gml file to string\n",
    "def gml_to_string(file):\n",
    "    gml_str = ''\n",
    "    with open(file, 'r') as file:\n",
    "        for line in file:\n",
    "            gml_str += line.rstrip()\n",
    "    return gml_str\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "gml_graph = gml_to_string('frontdoor_criterion_graph.gml')\n",
    "# With GML string\n",
    "model=CausalModel(\n",
    "        data = df,\n",
    "        treatment='X',\n",
    "        outcome='Y',\n",
    "        graph=gml_graph\n",
    "        )\n",
    "model.view_model()\n",
    "\n",
    "display(Image(filename=\"causal_model.png\", width = 200, height = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aa0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we extract the CausalGraph object from our CausalModel object\n",
    "our_causal_graph = model._graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7433b25",
   "metadata": {},
   "source": [
    "Now we can find an adjustment set that satisfies the frontdoor criterion. We first need all directed paths from $X$ to $Y$, as our adjustment set needs to intercept all such paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a652eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for finding all directed paths between the two nodes given\n",
    "our_causal_graph.get_all_directed_paths('X', 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952105d7",
   "metadata": {},
   "source": [
    "There is only one such directed path, and this path only contains the extra node $W$. So our only possible adjustment set is {$W$}. We now need to check whether this set satisfies the other requirements in the criterion.\n",
    "\n",
    "We first find all backdoor paths from $X$ to $W$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa91e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that finds backdoor paths from the first node to the second\n",
    "x_w_backdoor_paths = our_causal_graph.get_backdoor_paths('X', 'W')\n",
    "x_w_backdoor_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd73e39",
   "metadata": {},
   "source": [
    "For each of these paths, we need to confirm that they are blocked. As the adjustment set we are consider is only the node $W$, this blocking needs to be not conditioned on any other nodes (i.e. there needs to be a collider on each of these paths)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49948650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for keeping track of which paths are blocked\n",
    "path_is_blocked = []\n",
    "\n",
    "# looping through the backdoor paths from X to W\n",
    "for path in x_w_backdoor_paths:\n",
    "    # the is_blocked function checks with a path is blocked when conditioning on the set conditioned_nodes\n",
    "    # in this case, we are not conditioning on any nodes, so give it the empty set\n",
    "    path_is_blocked.append(our_causal_graph.is_blocked(path, conditioned_nodes = []))\n",
    "\n",
    "path_is_blocked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ff4966",
   "metadata": {},
   "source": [
    "We see that all of the paths are blocked. Looking at the graph, this is because the node $Y$ is a collider on each of the paths, and we are not conditioning on $Y$.\n",
    "\n",
    "Finally, we need to check that all backdoor paths from $W$ to $Y$ are blocked by $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fd8523",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_y_backdoor_paths = our_causal_graph.get_backdoor_paths('W', 'Y')\n",
    "w_y_backdoor_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e73642",
   "metadata": {},
   "source": [
    "For each of the above paths, we need to check whether they are blocked by $X$. We can do so in the same way as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157ad622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for keeping track of which paths are blocked\n",
    "path_is_blocked = []\n",
    "\n",
    "# looping through the backdoor paths from W to Y\n",
    "for path in w_y_backdoor_paths:\n",
    "    # the is_blocked function checks with a path is blocked when conditioning on the set conditioned_nodes\n",
    "    # in this case, we are conditioning on the set [X]\n",
    "    path_is_blocked.append(our_causal_graph.is_blocked(path, conditioned_nodes = ['X']))\n",
    "\n",
    "path_is_blocked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3da3531",
   "metadata": {},
   "source": [
    "We can see that all paths are blocked by $X$. Thus, the set {$W$} meets the frontdoor criterion and is a valid adjustment set for measuring the effect of $X$ on $Y$.\n",
    "\n",
    "As always, the process is completed by DoWhy in the background. We can see under Estimand 3 that it has correctly identified {$W$} as an adjustment set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84cb231",
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_estimand = model.identify_effect()\n",
    "print(identified_estimand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd9bf94",
   "metadata": {},
   "source": [
    "Most of the functions we have applied here are from the DoWhy CausalGraph object (https://github.com/microsoft/dowhy/blob/master/dowhy/causal_graph.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13258bed",
   "metadata": {},
   "source": [
    "### Instrumental variables\n",
    "\n",
    "Instrumental variables can be used when you have unobserved confounders, limiting your ability to apply backdoor or frontdoor criterion. In order for a variable $Z$ to qualify as an instrumental variable for measuring the effect of $X$ on $Y$, it needs to meet the following conditions<sup>[1]</sup>:\n",
    "1. $Z$ has a causal effect on $X$\n",
    "2. $Z$ affects the outcome $Y$ only through $X$\n",
    "3. $Z$ and $Y$ have no common causes\n",
    "\n",
    "[1] Instruments for Causal Inference (Hernan and Robins, 2006)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6d40fc",
   "metadata": {},
   "source": [
    "We will look at the example given by DoWhy at https://microsoft.github.io/dowhy/example_notebooks/dowhy-simple-iv-example.html.\n",
    "\n",
    "In this example, we want to estimate the effect of education on income. We assume there is a confounder, called 'ability', that impacts on both education and income, but we cannot observe this variable. Furthermore, we assume that there is an education voucher that affects education, but has no direct effect on income and is not affected by 'ability'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c17e8f",
   "metadata": {},
   "source": [
    "We create the graph showing this, where $U$ represents the unobservable, confounding 'ability'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2969866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "G.add_nodes_from(['voucher', 'education', 'U', 'income'])\n",
    "G.add_edges_from([('voucher','education'), ('education','income'), ('U','education'),\n",
    "                 ('U','income')])\n",
    "nx.write_gml(G, \"instrumental_variables_graph.gml\")\n",
    "\n",
    "# plotting with a slightly bigger plot and nodes placed in good positions\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,8))\n",
    "pos = {'voucher': (1,2), 'education': (1,1), 'U': (2,2), 'income': (2,0)}\n",
    "nx.draw(G, pos= pos, with_labels=True, node_size=4000, node_color='w', edgecolors ='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c8e0c1",
   "metadata": {},
   "source": [
    "If we were able to observe $U$, we could apply the backdoor criterion and condition on it. But, since we are assuming $U$ is unobservable, we instead need to use the 'voucher' variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435295dd",
   "metadata": {},
   "source": [
    "We can check if 'voucher' meets the conditions for an instrumental variable:\n",
    "1. It has a direct causal effect on 'education'\n",
    "2. There is no direct effect of 'voucher' on 'income'\n",
    "3. 'voucher' and 'income' share no common causes\n",
    "\n",
    "As it meets all conditions, we can use 'voucher' as an instrumental variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b409eb",
   "metadata": {},
   "source": [
    "As before, we can also identify this variable using DoWhy. In this case, we simply do not provide values for $U$ to the CausalModel, which tells it that the variable is unobserved.\n",
    "\n",
    "We start by simulating data for ability, voucher, education, and income. These data are not critical to understanding the application of instrumental variables, as we are currently more interested in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d8a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n_points = 1000\n",
    "education_abilty = 1\n",
    "education_voucher = 2\n",
    "income_abilty = 2\n",
    "income_education = 4\n",
    "\n",
    "# confounder\n",
    "ability = np.random.normal(0, 3, size=n_points)\n",
    "\n",
    "# instrument\n",
    "voucher = np.random.normal(2, 1, size=n_points)\n",
    "\n",
    "# treatment\n",
    "education = np.random.normal(5, 1, size=n_points) + education_abilty * ability +\\\n",
    "            education_voucher * voucher\n",
    "\n",
    "# outcome\n",
    "income = np.random.normal(10, 3, size=n_points) +\\\n",
    "         income_abilty * ability + income_education * education\n",
    "\n",
    "# build dataset (exclude confounder `ability` which we assume to be unobserved)\n",
    "data = np.stack([education, income, voucher]).T\n",
    "df = pd.DataFrame(data, columns = ['education', 'income', 'voucher'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5fbd9a",
   "metadata": {},
   "source": [
    "As before, we provide our graph, treatment and outcome variables, and the data to DoWhy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aedc31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create and display the causal graph we are assuming\n",
    "gml_graph = gml_to_string('instrumental_variables_graph.gml')\n",
    "model=CausalModel(\n",
    "        data = df,\n",
    "        treatment='education',\n",
    "        outcome='income',\n",
    "        graph=gml_graph\n",
    "        )\n",
    "model.view_model()\n",
    "from IPython.display import Image, display\n",
    "display(Image(filename=\"causal_model.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa30f1f",
   "metadata": {},
   "source": [
    "By not providing $U$ values, DoWhy recognises that the backdoor criterion cannot be used since we can no longer condition on $U$. However, it correctly identifies that we can use 'voucher' as an instrumental variable in Estimand 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdcccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_estimand = model.identify_effect()\n",
    "print(identified_estimand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b7fb96",
   "metadata": {},
   "source": [
    "Worth noting: there are also possible conditional instrumental variables in certain causal graphs. DoWhy is not able to identify these correctly, so be warned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196315be",
   "metadata": {},
   "source": [
    "### Estimating Causal Effects\n",
    "\n",
    "Now that we have seen how to identify valid adjustment sets, we wish to apply them to estimate a causal effect from our data. We choose which statistical methods to apply to estimate the effect based on our adjustment set.\n",
    "\n",
    "Let's look at an example using simulated linear data from DoWhy (https://microsoft.github.io/dowhy/example_notebooks/dowhy_simple_example.html). The true causal effect is beta = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc33be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dowhy.datasets\n",
    "\n",
    "# we generate linear data with beta = 10 being the true causal effect (this is the value we wish to estimate from the data)\n",
    "num_samples = 20000\n",
    "data = dowhy.datasets.linear_dataset(beta=10,\n",
    "        num_common_causes=5,\n",
    "        num_instruments = 2,\n",
    "        num_effect_modifiers=0,\n",
    "        num_samples=num_samples,\n",
    "        treatment_is_binary=True,\n",
    "        num_discrete_common_causes=1)\n",
    "df = data[\"df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099f4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0 is our (binary) treatment variable, and y is our outcome variable\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f34dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the data and the graph it is generated from to create a CausalModel object\n",
    "model=CausalModel(\n",
    "        data = df,\n",
    "        treatment=data[\"treatment_name\"],\n",
    "        outcome=data[\"outcome_name\"],\n",
    "        graph=data[\"gml_graph\"]\n",
    "        )\n",
    "\n",
    "model.view_model()\n",
    "display(Image(filename=\"causal_model.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e405ac43",
   "metadata": {},
   "source": [
    "We will not manually apply the backdoor criterion, frontdoor criterion, or instrumental variables; instead, we will simply use the valid adjustment sets found by DoWhy. We see that there are no sets satisfying the frontdoor criterion, but there are for the backdoor and instrumental variables. You can check yourself that these satisfy the criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af77e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "print(identified_estimand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5abdc63",
   "metadata": {},
   "source": [
    "Let's use the set identified by the backdoor criterion. We can thus estimate the effect of v0 on y when we condition on W0, W1, W2, W3, and W4.\n",
    "\n",
    "Let's first try estimate the effect without conditioning on these extra variables. Suppose we expect (know) that the effect is linear. We can then apply a linear estimator to find the effect. We will use linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e83e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first use only v0 and y\n",
    "# we need to reshape them into the correct shape for our linear regression function\n",
    "v0_vals = df['v0'].values.reshape(num_samples, 1)\n",
    "y_vals = df['y'].values.reshape(num_samples, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98572708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we import the LinearRegression object from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# we fit a linear regression model with v0 and y, and check what the estimated linear effect is\n",
    "linear_regressor = LinearRegression() \n",
    "linear_regressor.fit(v0_vals, y_vals)\n",
    "linear_regressor.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00041392",
   "metadata": {},
   "source": [
    "We see that the estimated linear effect is highly biased, but we expected this knowing we needed to condition on the correct sets. Let's try conditioning on only part of a valid adjustment set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0de5c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first collect the extra variables we wish to include\n",
    "W0_vals = df['W0'].values.reshape(num_samples, 1)\n",
    "W1_vals = df['W1'].values.reshape(num_samples, 1)\n",
    "\n",
    "# we need to combine all of the variables we're including into one array\n",
    "v0_W0_W1_vals = np.concatenate((v0_vals, W0_vals, W1_vals), axis = 1)\n",
    "v0_W0_W1_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397b16b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we fit the linear regression with the extra variables included\n",
    "linear_regressor.fit(v0_W0_W1_vals, y_vals)\n",
    "linear_regressor.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ac1ef0",
   "metadata": {},
   "source": [
    "We see that our estimate (the first coeffcient) is still biased. Now, we try using the correct conditioning set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8ee702",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2_vals = df['W2'].values.reshape(num_samples, 1)\n",
    "W3_vals = df['W3'].values.reshape(num_samples, 1)\n",
    "# W4 is a categorical value, so we use the pandas' get_dummy function to turn it into dummy variables\n",
    "W4_vals = pd.get_dummies(df['W4'].values).iloc[:,1:4]\n",
    "\n",
    "backdoor_vars = np.concatenate((v0_vals, W0_vals, W1_vals, W2_vals, W3_vals, W4_vals), axis = 1)\n",
    "backdoor_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b29959",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor.fit(backdoor_vars, y_vals)\n",
    "linear_regressor.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f8466f",
   "metadata": {},
   "source": [
    "Now our estimate (the first coefficient) is unbiased. So we would thus correctly conclude that our linear causal effect is 10.\n",
    "\n",
    "DoWhy allows you to estimate causal effects using different estimators based on the adjustment sets it identifies. We can do what we did above by calling the estimate_effect function on our identified_estimand and specifying which criterion we wish to use, and which estimator. The different estimators you can use are available here: https://github.com/microsoft/dowhy/tree/master/dowhy/causal_estimators. When calling the estimator, exclude the '_estimator' at the end.\n",
    "\n",
    "Below, we specify we want to use the adjustment set from the backdoor criterion and a linear regression estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da474479",
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_estimate = model.estimate_effect(identified_estimand,\n",
    "        method_name=\"backdoor.linear_regression\")\n",
    "print(causal_estimate)\n",
    "print(\"Causal Estimate is \" + str(causal_estimate.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb6d011",
   "metadata": {},
   "source": [
    "We see that we get the same estimate as when we performed the procedure manually. Let's try one other backdoor estimator and an instrumental variable estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d703e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the backdoor adjustment set and propensity score stratification\n",
    "causal_estimate = model.estimate_effect(identified_estimand,\n",
    "        method_name=\"backdoor.propensity_score_matching\")\n",
    "print(causal_estimate)\n",
    "print(\"Causal Estimate is \" + str(causal_estimate.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a95e1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the instrumental variables\n",
    "causal_estimate = model.estimate_effect(identified_estimand,\n",
    "        method_name=\"iv.instrumental_variable\")\n",
    "print(causal_estimate)\n",
    "print(\"Causal Estimate is \" + str(causal_estimate.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d8156b",
   "metadata": {},
   "source": [
    "Not every estimator will always give a good estimate. This depends on the true nature of the effect (linear, exponential, etc.), and the assumptions made by the estimator. We can do this one correctly using the IV notebook shown by Sara in class which implements 2SLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3266916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define a function to extract our linear regression coefficient\n",
    "def linear_coeff(X,Y):\n",
    "    linear_regressor = LinearRegression() \n",
    "    linear_regressor.fit(X, Y)\n",
    "    return linear_regressor.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bf7be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we reshape the variables we are going to use (Z1 is a sufficient instrumental variable)\n",
    "v0 = df['v0'].values.reshape(-1,1)\n",
    "z1 = df['Z1'].values.reshape(-1,1)\n",
    "y = df['y'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff8f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can calculate the linear effect that Z1 has on v0, and what our estimated linear v0 values are\n",
    "vhat = linear_coeff(z1, v0) * z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca035c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can finally calculate the linear effect of vhat on y\n",
    "linear_coeff(vhat, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
